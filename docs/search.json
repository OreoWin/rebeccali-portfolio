[
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "XGBoost vs.¬†SVM ‚Äî Classification and Decision Boundaries\nDec 2024\nSummary\nCompared the performance and decision boundaries of two popular machine learning algorithms ‚Äî XGBoost and Support Vector Machine (SVM) ‚Äî on a simulated binary classification dataset. The goal was to visualize how each model learns nonlinear boundaries and evaluate their relative performance on synthetic data.\nProcess\n\nGenerate 5,000 two-feature points with binary labels from a distance-to-origin rule.\nSplit data into train/test (80/20).\nTrain XGBoostClassifier and SVC with default hyperparameters.\nEvaluate train vs.¬†test accuracy.\nVisualize decision boundaries with Matplotlib.\n\nOutcome\n\nXGBoost: Train 99.95%, Test 98.7%.\nSVM: Train 99.2%, Test 99.0%.\nBoth high accuracy; SVM generalizes slightly better, while XGBoost is more adaptive with mild overfit risk.\n\nView code on GitHub Download .py{.btn .btn-outline-secondary download}\n\n\n\nCalifornia Wildfire Damage Analysis\nSummary\nInvestigated patterns and relationships among wildfire damage indicators across California using Principal Component Analysis (PCA) and Factor Analysis (FA). The goal was to uncover latent dimensions driving wildfire severity and evaluate the interdependence between physical and economic loss variables.\nProcess\n\nCollected and cleaned wildfire damage data (acres burned, homes/businesses destroyed, vehicles damaged, injuries, fatalities, financial loss).\nReplaced missing numeric values with mean imputation; standardized continuous variables.\nPerformed PCA to reduce dimensionality and visualize factor contributions to total variance.\nConducted Factor Analysis (MLE + Varimax) to identify constructs explaining correlated damage metrics.\nEvaluated factor adequacy via KMO (= 0.5) and Bartlett‚Äôs test (p = 0.69).\n\nOutcome\n\nFirst two principal components explained ~37% of total variance, with Area Burned and Financial Loss dominant.\nFactor Analysis revealed two interpretable factors: (1) property/economic damage and (2) physical impact/casualties.\nFindings suggest financial losses correlate strongly with infrastructure destruction, while injuries/fatalities form a distinct severity dimension.\n\nCalifornia Wildfire Damage Analysis\n\n\n\nPortfolio Construction and Risk Analysis\nFeb 2025\nSummary\nFocused on portfolio optimization and risk evaluation using real-world stock data from the technology and financial sectors. The goal was to construct and analyze multiple portfolio types‚Äîincluding Minimum Variance, Tangency, and Target Return portfolios‚Äîacross different time periods, and to assess their performance using modern portfolio theory and CAPM.\nProcess\n\nCollected daily/monthly prices (2020‚Äì2023) and computed log-returns.\nApplied Markowitz Mean‚ÄìVariance Optimization in R under a no-short-selling constraint for 5%, 7.5%, 10%, 12.5%, and 15% target returns.\nComputed Tangency and Minimum Variance portfolios, using a dynamic risk-free rate from 10-year U.S. Treasury yields.\nRan CAPM to estimate alpha/beta vs.¬†SPY and QQQ; tested significance to gauge market efficiency.\nEstimated Value-at-Risk (VaR) with a multivariate t-distribution to quantify downside risk.\n\nOutcome\n\nIncluding financial sector stocks improved diversification and reduced volatility.\nTangency portfolios achieved the highest Sharpe ratios (better risk-adjusted returns).\nCAPM results showed most alphas were statistically insignificant (consistent with market efficiency).\nVaR indicated Tangency portfolios carry higher potential downside risk yet deliver superior long-term returns.\n\nPortfolio Construction and Risk Analysis"
  },
  {
    "objectID": "CV.html",
    "href": "CV.html",
    "title": "CV",
    "section": "",
    "text": "Download CV Download Resume\n\n\nSkills\n\nSQL (HiveQL, MySQL)\n\nPython (NumPy, Pandas, Matplotlib)\n\nAirflow (workflow orchestration)\n\nK-means Clustering (unsupervised learning)\n\nTableau / Power BI / SPSS (interactive dashboards & analytics)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "",
    "section": "",
    "text": "Welcome! I‚Äôm Rebecca Li, currently pursuing an M.S. in Applied Statistics and Data Science at UCLA. Prior to UCLA, I earned dual B.A. degrees in Statistics and Economics from UC Davis.\nI‚Äôm passionate about uncovering the stories behind data ‚Äî finding the patterns that explain human behavior and the insights that drive better decisions. My interest in marketing analytics began during my internship at Li Auto, where I analyzed intelligent driving and referral data to understand user behavior. That experience sparked a deeper curiosity about how data can guide real-world business strategy.\nNow, I‚Äôm conducting market research and marketing analysis for AutoUnify where I explore how data integration can empower the automotive industry.\nGraduating June 2026 | Actively seeking full-time opportunities\nüìß rebeccaisme12138@gmail.com\nresume"
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "üìß rebeccali@ucla.edu\nüíº LinkedIn\nüêô GitHub"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "If you are not redirected automatically, go to About."
  }
]